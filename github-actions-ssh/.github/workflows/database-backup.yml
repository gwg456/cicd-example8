name: æ•°æ®åº“å¤‡ä»½ä¸ç®¡ç†

on:
  schedule:
    # æ¯å¤©å‡Œæ™¨ 2 ç‚¹è‡ªåŠ¨å¤‡ä»½
    - cron: '0 2 * * *'
    # æ¯å‘¨æ—¥å‡Œæ™¨ 1 ç‚¹è¿›è¡Œå®Œæ•´å¤‡ä»½
    - cron: '0 1 * * 0'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'å¤‡ä»½ç±»å‹'
        required: true
        default: 'incremental'
        type: choice
        options:
        - incremental
        - full
        - schema_only
      databases:
        description: 'æ•°æ®åº“åç§° (é€—å·åˆ†éš”ï¼Œç©ºä¸ºå…¨éƒ¨)'
        required: false
        default: ''
      retention_days:
        description: 'ä¿ç•™å¤©æ•°'
        required: false
        default: '7'

env:
  BACKUP_DIR: '/backup/database'
  S3_BUCKET: 'my-app-backups'

jobs:
  prepare-backup:
    runs-on: ubuntu-latest
    name: å‡†å¤‡å¤‡ä»½
    outputs:
      backup-type: ${{ steps.setup.outputs.backup-type }}
      databases: ${{ steps.setup.outputs.databases }}
      timestamp: ${{ steps.setup.outputs.timestamp }}
      retention-days: ${{ steps.setup.outputs.retention-days }}
      
    steps:
    - name: è®¾ç½®å¤‡ä»½å‚æ•°
      id: setup
      run: |
        # è®¾ç½®æ—¶é—´æˆ³
        timestamp=$(date +%Y%m%d_%H%M%S)
        echo "timestamp=$timestamp" >> $GITHUB_OUTPUT
        
        # ç¡®å®šå¤‡ä»½ç±»å‹
        if [ "${{ github.event_name }}" == "schedule" ]; then
          if [ "${{ github.event.schedule }}" == "0 1 * * 0" ]; then
            backup_type="full"
            retention_days="30"
          else
            backup_type="incremental"
            retention_days="7"
          fi
        else
          backup_type="${{ github.event.inputs.backup_type || 'incremental' }}"
          retention_days="${{ github.event.inputs.retention_days || '7' }}"
        fi
        
        echo "backup-type=$backup_type" >> $GITHUB_OUTPUT
        echo "retention-days=$retention_days" >> $GITHUB_OUTPUT
        
        # è®¾ç½®æ•°æ®åº“åˆ—è¡¨
        if [ -n "${{ github.event.inputs.databases }}" ]; then
          databases="${{ github.event.inputs.databases }}"
        else
          databases="myapp_prod,myapp_analytics,myapp_logs"
        fi
        echo "databases=$databases" >> $GITHUB_OUTPUT
        
        echo "ğŸ“‹ å¤‡ä»½é…ç½®:"
        echo "- ç±»å‹: $backup_type"
        echo "- æ•°æ®åº“: $databases"
        echo "- æ—¶é—´æˆ³: $timestamp"
        echo "- ä¿ç•™å¤©æ•°: $retention_days"

  mysql-backup:
    runs-on: ubuntu-latest
    needs: prepare-backup
    name: MySQL æ•°æ®åº“å¤‡ä»½
    
    steps:
    - name: Checkout ä»£ç 
      uses: actions/checkout@v4
      
    - name: æ‰§è¡Œ MySQL å¤‡ä»½
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.MYSQL_SSH_HOST }}
        username: ${{ secrets.MYSQL_SSH_USERNAME }}
        key: ${{ secrets.MYSQL_SSH_PRIVATE_KEY }}
        port: ${{ secrets.MYSQL_SSH_PORT || 22 }}
        envs: BACKUP_TYPE,DATABASES,TIMESTAMP,RETENTION_DAYS
        script: |
          set -e
          
          echo "ğŸ—„ï¸ å¼€å§‹ MySQL æ•°æ®åº“å¤‡ä»½..."
          echo "å¤‡ä»½ç±»å‹: $BACKUP_TYPE"
          echo "æ•°æ®åº“: $DATABASES"
          echo "æ—¶é—´æˆ³: $TIMESTAMP"
          
          # åˆ›å»ºå¤‡ä»½ç›®å½•
          sudo mkdir -p ${{ env.BACKUP_DIR }}/mysql/$TIMESTAMP
          cd ${{ env.BACKUP_DIR }}/mysql/$TIMESTAMP
          
          # æ•°æ®åº“è¿æ¥å‚æ•°
          MYSQL_HOST="${{ secrets.MYSQL_HOST }}"
          MYSQL_PORT="${{ secrets.MYSQL_PORT || 3306 }}"
          MYSQL_USER="${{ secrets.MYSQL_USER }}"
          MYSQL_PASSWORD="${{ secrets.MYSQL_PASSWORD }}"
          
          # åˆ†å‰²æ•°æ®åº“åˆ—è¡¨
          IFS=',' read -ra DB_ARRAY <<< "$DATABASES"
          
          for db in "${DB_ARRAY[@]}"; do
            db=$(echo "$db" | xargs)  # å»é™¤ç©ºæ ¼
            echo "ğŸ“¦ å¤‡ä»½æ•°æ®åº“: $db"
            
            case "$BACKUP_TYPE" in
              "full")
                # å®Œæ•´å¤‡ä»½
                mysqldump \
                  --host="$MYSQL_HOST" \
                  --port="$MYSQL_PORT" \
                  --user="$MYSQL_USER" \
                  --password="$MYSQL_PASSWORD" \
                  --single-transaction \
                  --routines \
                  --triggers \
                  --events \
                  --hex-blob \
                  --master-data=2 \
                  --flush-logs \
                  "$db" | gzip > "${db}_full_${TIMESTAMP}.sql.gz"
                ;;
                
              "incremental")
                # å¢é‡å¤‡ä»½ (åŸºäº binlog)
                mysqldump \
                  --host="$MYSQL_HOST" \
                  --port="$MYSQL_PORT" \
                  --user="$MYSQL_USER" \
                  --password="$MYSQL_PASSWORD" \
                  --single-transaction \
                  --master-data=2 \
                  --flush-logs \
                  "$db" | gzip > "${db}_incremental_${TIMESTAMP}.sql.gz"
                  
                # å¤åˆ¶ binlog æ–‡ä»¶
                sudo cp /var/log/mysql/mysql-bin.* . 2>/dev/null || echo "âš ï¸ æ— æ³•å¤åˆ¶ binlog æ–‡ä»¶"
                ;;
                
              "schema_only")
                # ä»…ç»“æ„å¤‡ä»½
                mysqldump \
                  --host="$MYSQL_HOST" \
                  --port="$MYSQL_PORT" \
                  --user="$MYSQL_USER" \
                  --password="$MYSQL_PASSWORD" \
                  --no-data \
                  --routines \
                  --triggers \
                  --events \
                  "$db" | gzip > "${db}_schema_${TIMESTAMP}.sql.gz"
                ;;
            esac
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            if [ -f "${db}_${BACKUP_TYPE}_${TIMESTAMP}.sql.gz" ]; then
              file_size=$(stat -c%s "${db}_${BACKUP_TYPE}_${TIMESTAMP}.sql.gz")
              if [ $file_size -gt 0 ]; then
                echo "âœ… $db å¤‡ä»½æˆåŠŸ (${file_size} bytes)"
              else
                echo "âŒ $db å¤‡ä»½æ–‡ä»¶ä¸ºç©º"
                exit 1
              fi
            else
              echo "âŒ $db å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
              exit 1
            fi
          done
          
          # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
          cat > backup_metadata.json << EOF
          {
            "backup_time": "$(date -Iseconds)",
            "backup_type": "$BACKUP_TYPE",
            "databases": "$DATABASES",
            "mysql_version": "$(mysql --version)",
            "server_info": "$(uname -a)",
            "backup_size": "$(du -sh . | cut -f1)"
          }
          EOF
          
          echo "ğŸ“Š å¤‡ä»½å…ƒæ•°æ®:"
          cat backup_metadata.json
          
          # è®¡ç®—æ ¡éªŒå’Œ
          echo "ğŸ” è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ..."
          sha256sum *.gz > checksums.sha256
          
          echo "âœ… MySQL å¤‡ä»½å®Œæˆ"
      env:
        BACKUP_TYPE: ${{ needs.prepare-backup.outputs.backup-type }}
        DATABASES: ${{ needs.prepare-backup.outputs.databases }}
        TIMESTAMP: ${{ needs.prepare-backup.outputs.timestamp }}
        RETENTION_DAYS: ${{ needs.prepare-backup.outputs.retention-days }}

  postgresql-backup:
    runs-on: ubuntu-latest
    needs: prepare-backup
    name: PostgreSQL æ•°æ®åº“å¤‡ä»½
    
    steps:
    - name: æ‰§è¡Œ PostgreSQL å¤‡ä»½
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.POSTGRES_SSH_HOST }}
        username: ${{ secrets.POSTGRES_SSH_USERNAME }}
        key: ${{ secrets.POSTGRES_SSH_PRIVATE_KEY }}
        port: ${{ secrets.POSTGRES_SSH_PORT || 22 }}
        envs: BACKUP_TYPE,DATABASES,TIMESTAMP,RETENTION_DAYS
        script: |
          set -e
          
          echo "ğŸ˜ å¼€å§‹ PostgreSQL æ•°æ®åº“å¤‡ä»½..."
          echo "å¤‡ä»½ç±»å‹: $BACKUP_TYPE"
          echo "æ•°æ®åº“: $DATABASES"
          echo "æ—¶é—´æˆ³: $TIMESTAMP"
          
          # è®¾ç½® PostgreSQL ç¯å¢ƒå˜é‡
          export PGHOST="${{ secrets.POSTGRES_HOST }}"
          export PGPORT="${{ secrets.POSTGRES_PORT || 5432 }}"
          export PGUSER="${{ secrets.POSTGRES_USER }}"
          export PGPASSWORD="${{ secrets.POSTGRES_PASSWORD }}"
          
          # åˆ›å»ºå¤‡ä»½ç›®å½•
          sudo mkdir -p ${{ env.BACKUP_DIR }}/postgresql/$TIMESTAMP
          cd ${{ env.BACKUP_DIR }}/postgresql/$TIMESTAMP
          
          # åˆ†å‰²æ•°æ®åº“åˆ—è¡¨
          IFS=',' read -ra DB_ARRAY <<< "$DATABASES"
          
          for db in "${DB_ARRAY[@]}"; do
            db=$(echo "$db" | xargs)  # å»é™¤ç©ºæ ¼
            echo "ğŸ“¦ å¤‡ä»½æ•°æ®åº“: $db"
            
            case "$BACKUP_TYPE" in
              "full")
                # å®Œæ•´å¤‡ä»½ (è‡ªå®šä¹‰æ ¼å¼ï¼Œæ”¯æŒå¹¶è¡Œæ¢å¤)
                pg_dump \
                  --format=custom \
                  --compress=9 \
                  --verbose \
                  --file="${db}_full_${TIMESTAMP}.dump" \
                  "$db"
                  
                # åŒæ—¶åˆ›å»º SQL æ ¼å¼å¤‡ä»½
                pg_dump \
                  --format=plain \
                  --verbose \
                  "$db" | gzip > "${db}_full_${TIMESTAMP}.sql.gz"
                ;;
                
              "incremental")
                # PostgreSQL å¢é‡å¤‡ä»½ (ä½¿ç”¨ WAL)
                pg_dump \
                  --format=custom \
                  --compress=9 \
                  --verbose \
                  --file="${db}_incremental_${TIMESTAMP}.dump" \
                  "$db"
                  
                # å½’æ¡£ WAL æ–‡ä»¶
                echo "ğŸ“‚ å½’æ¡£ WAL æ–‡ä»¶..."
                sudo find /var/lib/postgresql/*/main/pg_wal -name "*.ready" -type f | \
                  sudo xargs -I {} cp {} ./ 2>/dev/null || echo "âš ï¸ æ— æ³•å¤åˆ¶ WAL æ–‡ä»¶"
                ;;
                
              "schema_only")
                # ä»…ç»“æ„å¤‡ä»½
                pg_dump \
                  --schema-only \
                  --format=plain \
                  --verbose \
                  "$db" | gzip > "${db}_schema_${TIMESTAMP}.sql.gz"
                ;;
            esac
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            backup_file="${db}_${BACKUP_TYPE}_${TIMESTAMP}.dump"
            sql_file="${db}_${BACKUP_TYPE}_${TIMESTAMP}.sql.gz"
            
            if [ -f "$backup_file" ] || [ -f "$sql_file" ]; then
              if [ -f "$backup_file" ]; then
                file_size=$(stat -c%s "$backup_file")
                echo "âœ… $db å¤‡ä»½æˆåŠŸ (dump: ${file_size} bytes)"
              fi
              if [ -f "$sql_file" ]; then
                file_size=$(stat -c%s "$sql_file")
                echo "âœ… $db å¤‡ä»½æˆåŠŸ (sql: ${file_size} bytes)"
              fi
            else
              echo "âŒ $db å¤‡ä»½å¤±è´¥"
              exit 1
            fi
          done
          
          # å¤‡ä»½å…¨å±€å¯¹è±¡ (ç”¨æˆ·ã€è§’è‰²ç­‰)
          echo "ğŸ‘¥ å¤‡ä»½å…¨å±€å¯¹è±¡..."
          pg_dumpall --globals-only | gzip > "globals_${TIMESTAMP}.sql.gz"
          
          # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
          cat > backup_metadata.json << EOF
          {
            "backup_time": "$(date -Iseconds)",
            "backup_type": "$BACKUP_TYPE",
            "databases": "$DATABASES",
            "postgresql_version": "$(psql --version)",
            "server_info": "$(uname -a)",
            "backup_size": "$(du -sh . | cut -f1)"
          }
          EOF
          
          echo "ğŸ“Š å¤‡ä»½å…ƒæ•°æ®:"
          cat backup_metadata.json
          
          # è®¡ç®—æ ¡éªŒå’Œ
          echo "ğŸ” è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ..."
          sha256sum * > checksums.sha256
          
          echo "âœ… PostgreSQL å¤‡ä»½å®Œæˆ"
      env:
        BACKUP_TYPE: ${{ needs.prepare-backup.outputs.backup-type }}
        DATABASES: ${{ needs.prepare-backup.outputs.databases }}
        TIMESTAMP: ${{ needs.prepare-backup.outputs.timestamp }}
        RETENTION_DAYS: ${{ needs.prepare-backup.outputs.retention-days }}

  upload-to-cloud:
    runs-on: ubuntu-latest
    needs: [prepare-backup, mysql-backup, postgresql-backup]
    name: ä¸Šä¼ å¤‡ä»½åˆ°äº‘å­˜å‚¨
    
    steps:
    - name: ä¸Šä¼  MySQL å¤‡ä»½åˆ° S3
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.MYSQL_SSH_HOST }}
        username: ${{ secrets.MYSQL_SSH_USERNAME }}
        key: ${{ secrets.MYSQL_SSH_PRIVATE_KEY }}
        port: ${{ secrets.MYSQL_SSH_PORT || 22 }}
        envs: TIMESTAMP,S3_BUCKET
        script: |
          echo "â˜ï¸ ä¸Šä¼  MySQL å¤‡ä»½åˆ° S3..."
          
          # é…ç½® AWS CLI
          export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
          export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          export AWS_DEFAULT_REGION="${{ secrets.AWS_REGION }}"
          
          backup_dir="${{ env.BACKUP_DIR }}/mysql/$TIMESTAMP"
          
          if [ -d "$backup_dir" ]; then
            cd "$backup_dir"
            
            # ä¸Šä¼ æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            aws s3 sync . "s3://$S3_BUCKET/mysql/$TIMESTAMP/" \
              --storage-class STANDARD_IA \
              --metadata "backup-type=${{ needs.prepare-backup.outputs.backup-type }},created-by=github-actions"
              
            echo "âœ… MySQL å¤‡ä»½å·²ä¸Šä¼ åˆ° S3"
          else
            echo "âš ï¸ MySQL å¤‡ä»½ç›®å½•ä¸å­˜åœ¨"
          fi
      env:
        TIMESTAMP: ${{ needs.prepare-backup.outputs.timestamp }}
        S3_BUCKET: ${{ env.S3_BUCKET }}
        
    - name: ä¸Šä¼  PostgreSQL å¤‡ä»½åˆ° S3
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.POSTGRES_SSH_HOST }}
        username: ${{ secrets.POSTGRES_SSH_USERNAME }}
        key: ${{ secrets.POSTGRES_SSH_PRIVATE_KEY }}
        port: ${{ secrets.POSTGRES_SSH_PORT || 22 }}
        envs: TIMESTAMP,S3_BUCKET
        script: |
          echo "â˜ï¸ ä¸Šä¼  PostgreSQL å¤‡ä»½åˆ° S3..."
          
          # é…ç½® AWS CLI
          export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
          export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
          export AWS_DEFAULT_REGION="${{ secrets.AWS_REGION }}"
          
          backup_dir="${{ env.BACKUP_DIR }}/postgresql/$TIMESTAMP"
          
          if [ -d "$backup_dir" ]; then
            cd "$backup_dir"
            
            # ä¸Šä¼ æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            aws s3 sync . "s3://$S3_BUCKET/postgresql/$TIMESTAMP/" \
              --storage-class STANDARD_IA \
              --metadata "backup-type=${{ needs.prepare-backup.outputs.backup-type }},created-by=github-actions"
              
            echo "âœ… PostgreSQL å¤‡ä»½å·²ä¸Šä¼ åˆ° S3"
          else
            echo "âš ï¸ PostgreSQL å¤‡ä»½ç›®å½•ä¸å­˜åœ¨"
          fi
      env:
        TIMESTAMP: ${{ needs.prepare-backup.outputs.timestamp }}
        S3_BUCKET: ${{ env.S3_BUCKET }}

  cleanup-old-backups:
    runs-on: ubuntu-latest
    needs: [prepare-backup, upload-to-cloud]
    name: æ¸…ç†æ—§å¤‡ä»½
    
    steps:
    - name: æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.MYSQL_SSH_HOST }}
        username: ${{ secrets.MYSQL_SSH_USERNAME }}
        key: ${{ secrets.MYSQL_SSH_PRIVATE_KEY }}
        port: ${{ secrets.MYSQL_SSH_PORT || 22 }}
        envs: RETENTION_DAYS
        script: |
          echo "ğŸ§¹ æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½..."
          
          # æ¸…ç† MySQL å¤‡ä»½
          if [ -d "${{ env.BACKUP_DIR }}/mysql" ]; then
            find "${{ env.BACKUP_DIR }}/mysql" -type d -mtime +$RETENTION_DAYS -exec rm -rf {} + 2>/dev/null || true
            echo "âœ… MySQL æœ¬åœ°æ—§å¤‡ä»½å·²æ¸…ç†"
          fi
          
          # æ¸…ç† PostgreSQL å¤‡ä»½
          if [ -d "${{ env.BACKUP_DIR }}/postgresql" ]; then
            find "${{ env.BACKUP_DIR }}/postgresql" -type d -mtime +$RETENTION_DAYS -exec rm -rf {} + 2>/dev/null || true
            echo "âœ… PostgreSQL æœ¬åœ°æ—§å¤‡ä»½å·²æ¸…ç†"
          fi
          
          # æ˜¾ç¤ºå½“å‰å¤‡ä»½å ç”¨ç©ºé—´
          echo "ğŸ“Š å½“å‰å¤‡ä»½å ç”¨ç©ºé—´:"
          du -sh "${{ env.BACKUP_DIR }}"/* 2>/dev/null || echo "æ— å¤‡ä»½æ–‡ä»¶"
      env:
        RETENTION_DAYS: ${{ needs.prepare-backup.outputs.retention-days }}
        
    - name: æ¸…ç† S3 æ—§å¤‡ä»½
      run: |
        echo "â˜ï¸ æ¸…ç† S3 æ—§å¤‡ä»½..."
        
        # é…ç½® AWS CLI
        export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
        export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
        export AWS_DEFAULT_REGION="${{ secrets.AWS_REGION }}"
        
        # è®¡ç®—æˆªæ­¢æ—¥æœŸ
        cutoff_date=$(date -d "${{ needs.prepare-backup.outputs.retention-days }} days ago" +%Y%m%d)
        
        # æ¸…ç†æ—§çš„ MySQL å¤‡ä»½
        aws s3 ls "s3://${{ env.S3_BUCKET }}/mysql/" | while read -r line; do
          folder_date=$(echo "$line" | awk '{print $2}' | sed 's/\///g' | cut -c1-8)
          if [ "$folder_date" -lt "$cutoff_date" ]; then
            folder_name=$(echo "$line" | awk '{print $2}')
            echo "ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: mysql/$folder_name"
            aws s3 rm "s3://${{ env.S3_BUCKET }}/mysql/$folder_name" --recursive
          fi
        done
        
        # æ¸…ç†æ—§çš„ PostgreSQL å¤‡ä»½
        aws s3 ls "s3://${{ env.S3_BUCKET }}/postgresql/" | while read -r line; do
          folder_date=$(echo "$line" | awk '{print $2}' | sed 's/\///g' | cut -c1-8)
          if [ "$folder_date" -lt "$cutoff_date" ]; then
            folder_name=$(echo "$line" | awk '{print $2}')
            echo "ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: postgresql/$folder_name"
            aws s3 rm "s3://${{ env.S3_BUCKET }}/postgresql/$folder_name" --recursive
          fi
        done
        
        echo "âœ… S3 æ—§å¤‡ä»½æ¸…ç†å®Œæˆ"

  backup-verification:
    runs-on: ubuntu-latest
    needs: [prepare-backup, mysql-backup, postgresql-backup]
    name: å¤‡ä»½éªŒè¯
    
    steps:
    - name: éªŒè¯ MySQL å¤‡ä»½
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.MYSQL_SSH_HOST }}
        username: ${{ secrets.MYSQL_SSH_USERNAME }}
        key: ${{ secrets.MYSQL_SSH_PRIVATE_KEY }}
        port: ${{ secrets.MYSQL_SSH_PORT || 22 }}
        envs: TIMESTAMP
        script: |
          echo "ğŸ” éªŒè¯ MySQL å¤‡ä»½..."
          
          backup_dir="${{ env.BACKUP_DIR }}/mysql/$TIMESTAMP"
          cd "$backup_dir"
          
          # éªŒè¯æ ¡éªŒå’Œ
          if sha256sum -c checksums.sha256; then
            echo "âœ… MySQL å¤‡ä»½æ–‡ä»¶æ ¡éªŒå’ŒéªŒè¯é€šè¿‡"
          else
            echo "âŒ MySQL å¤‡ä»½æ–‡ä»¶æ ¡éªŒå’ŒéªŒè¯å¤±è´¥"
            exit 1
          fi
          
          # æµ‹è¯•å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§
          for gz_file in *.sql.gz; do
            if [ -f "$gz_file" ]; then
              if gunzip -t "$gz_file"; then
                echo "âœ… $gz_file æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡"
              else
                echo "âŒ $gz_file æ–‡ä»¶æŸå"
                exit 1
              fi
            fi
          done
      env:
        TIMESTAMP: ${{ needs.prepare-backup.outputs.timestamp }}

  notification:
    runs-on: ubuntu-latest
    needs: [prepare-backup, mysql-backup, postgresql-backup, upload-to-cloud, cleanup-old-backups, backup-verification]
    if: always()
    name: å‘é€é€šçŸ¥
    
    steps:
    - name: å‘é€å¤‡ä»½çŠ¶æ€é€šçŸ¥
      uses: 8398a7/action-slack@v3
      with:
        status: custom
        custom_payload: |
          {
            "text": "ğŸ—„ï¸ æ•°æ®åº“å¤‡ä»½æŠ¥å‘Š",
            "attachments": [
              {
                "color": "${{ contains(needs.*.result, 'failure') && 'danger' || 'good' }}",
                "fields": [
                  {
                    "title": "å¤‡ä»½ç±»å‹",
                    "value": "${{ needs.prepare-backup.outputs.backup-type }}",
                    "short": true
                  },
                  {
                    "title": "æ—¶é—´æˆ³",
                    "value": "${{ needs.prepare-backup.outputs.timestamp }}",
                    "short": true
                  },
                  {
                    "title": "MySQL å¤‡ä»½",
                    "value": "${{ needs.mysql-backup.result }}",
                    "short": true
                  },
                  {
                    "title": "PostgreSQL å¤‡ä»½",
                    "value": "${{ needs.postgresql-backup.result }}",
                    "short": true
                  },
                  {
                    "title": "äº‘å­˜å‚¨ä¸Šä¼ ",
                    "value": "${{ needs.upload-to-cloud.result }}",
                    "short": true
                  },
                  {
                    "title": "å¤‡ä»½éªŒè¯",
                    "value": "${{ needs.backup-verification.result }}",
                    "short": true
                  }
                ]
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}